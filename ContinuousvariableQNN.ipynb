{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "60522e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import strawberryfields as sf\n",
    "from strawberryfields import ops\n",
    "import logging\n",
    "tf.get_logger().setLevel(logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c61d5877",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(\"TensorFlow version:\", tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3c0e5552",
   "metadata": {},
   "outputs": [],
   "source": [
    "def interferometer(params, q):\n",
    "    \"\"\"Parameterised interferometer acting on ``N`` modes.\n",
    "\n",
    "    Args:\n",
    "        params (list[float]): list of length ``max(1, N-1) + (N-1)*N`` parameters.\n",
    "\n",
    "            * The first ``N(N-1)/2`` parameters correspond to the beamsplitter angles\n",
    "            * The second ``N(N-1)/2`` parameters correspond to the beamsplitter phases\n",
    "            * The final ``N-1`` parameters correspond to local rotation on the first N-1 modes\n",
    "\n",
    "        q (list[RegRef]): list of Strawberry Fields quantum registers the interferometer\n",
    "            is to be applied to\n",
    "    \"\"\"\n",
    "    N = len(q)\n",
    "    theta = params[:N*(N-1)//2]\n",
    "    phi = params[N*(N-1)//2:N*(N-1)]\n",
    "    rphi = params[-N+1:]\n",
    "\n",
    "    if N == 1:\n",
    "        # the interferometer is a single rotation\n",
    "        ops.Rgate(rphi[0]) | q[0]\n",
    "        return\n",
    "\n",
    "    n = 0  # keep track of free parameters\n",
    "\n",
    "    # Apply the rectangular beamsplitter array\n",
    "    # The array depth is N\n",
    "    for l in range(N):\n",
    "        for k, (q1, q2) in enumerate(zip(q[:-1], q[1:])):\n",
    "            # skip even or odd pairs depending on layer\n",
    "            if (l + k) % 2 != 1:\n",
    "                ops.BSgate(theta[n], phi[n]) | (q1, q2)\n",
    "                n += 1\n",
    "\n",
    "    # apply the final local phase shifts to all modes except the last one\n",
    "    for i in range(max(1, N - 1)):\n",
    "        ops.Rgate(rphi[i]) | q[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b3450076",
   "metadata": {},
   "outputs": [],
   "source": [
    "def layer(params, q):\n",
    "    \"\"\"CV quantum neural network layer acting on ``N`` modes.\n",
    "\n",
    "    Args:\n",
    "        params (list[float]): list of length ``2*(max(1, N-1) + N**2 + n)`` containing\n",
    "            the number of parameters for the layer\n",
    "        q (list[RegRef]): list of Strawberry Fields quantum registers the layer\n",
    "            is to be applied to\n",
    "    \"\"\"\n",
    "    N = len(q)\n",
    "    M = int(N * (N - 1)) + max(1, N - 1)\n",
    "\n",
    "    int1 = params[:M]\n",
    "    s = params[M:M+N]\n",
    "    int2 = params[M+N:2*M+N]\n",
    "    dr = params[2*M+N:2*M+2*N]\n",
    "    dp = params[2*M+2*N:2*M+3*N]\n",
    "    k = params[2*M+3*N:2*M+4*N]\n",
    "\n",
    "    # begin layer\n",
    "    interferometer(int1, q)\n",
    "\n",
    "    for i in range(N):\n",
    "        ops.Sgate(s[i]) | q[i]\n",
    "\n",
    "    interferometer(int2, q)\n",
    "\n",
    "    for i in range(N):\n",
    "        ops.Dgate(dr[i], dp[i]) | q[i]\n",
    "        ops.Kgate(k[i]) | q[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2c24faeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_weights(modes, layers, active_sd=0.0001, passive_sd=0.1):\n",
    "    \"\"\"Initialize a 2D TensorFlow Variable containing normally-distributed\n",
    "    random weights for an ``N`` mode quantum neural network with ``L`` layers.\n",
    "\n",
    "    Args:\n",
    "        modes (int): the number of modes in the quantum neural network\n",
    "        layers (int): the number of layers in the quantum neural network\n",
    "        active_sd (float): the standard deviation used when initializing\n",
    "            the normally-distributed weights for the active parameters\n",
    "            (displacement, squeezing, and Kerr magnitude)\n",
    "        passive_sd (float): the standard deviation used when initializing\n",
    "            the normally-distributed weights for the passive parameters\n",
    "            (beamsplitter angles and all gate phases)\n",
    "\n",
    "    Returns:\n",
    "        tf.Variable[tf.float32]: A TensorFlow Variable of shape\n",
    "        ``[layers, 2*(max(1, modes-1) + modes**2 + modes)]``, where the Lth\n",
    "        row represents the layer parameters for the Lth layer.\n",
    "    \"\"\"\n",
    "    # Number of interferometer parameters:\n",
    "    M = int(modes * (modes - 1)) + max(1, modes - 1)\n",
    "\n",
    "    # Create the TensorFlow variables\n",
    "    int1_weights = tf.random.normal(shape=[layers, M], stddev=passive_sd)\n",
    "    s_weights = tf.random.normal(shape=[layers, modes], stddev=active_sd)\n",
    "    int2_weights = tf.random.normal(shape=[layers, M], stddev=passive_sd)\n",
    "    dr_weights = tf.random.normal(shape=[layers, modes], stddev=active_sd)\n",
    "    dp_weights = tf.random.normal(shape=[layers, modes], stddev=passive_sd)\n",
    "    k_weights = tf.random.normal(shape=[layers, modes], stddev=active_sd)\n",
    "\n",
    "    weights = tf.concat(\n",
    "        [int1_weights, s_weights, int2_weights, dr_weights, dp_weights, k_weights], axis=1\n",
    "    )\n",
    "\n",
    "    weights = tf.Variable(weights)\n",
    "    #weights = tf.cast(weights, tf.complex64)\n",
    "\n",
    "    return weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c0961ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the random seed\n",
    "tf.random.set_seed(137)\n",
    "np.random.seed(137)\n",
    "\n",
    "\n",
    "# define width and depth of CV quantum neural network\n",
    "modes = 1\n",
    "layers = 8\n",
    "cutoff_dim = 6\n",
    "\n",
    "\n",
    "# defining desired state (single photon state)\n",
    "target_state = np.zeros(cutoff_dim)\n",
    "target_state[1] = 1\n",
    "target_state = tf.constant(target_state, dtype=tf.complex64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "09d1a534",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize engine and program\n",
    "eng = sf.Engine(backend=\"tf\", backend_options={\"cutoff_dim\": cutoff_dim})\n",
    "qnn = sf.Program(modes)\n",
    "\n",
    "# initialize QNN weights\n",
    "weights = init_weights(modes, layers) # our TensorFlow weights\n",
    "num_params = np.prod(weights.shape)   # total number of parameters in our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "929ef1d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create array of Strawberry Fields symbolic gate arguments, matching\n",
    "# the size of the weights Variable.\n",
    "sf_params = np.arange(num_params).reshape(weights.shape).astype(str)\n",
    "sf_params = np.array([qnn.params(*i) for i in sf_params])\n",
    "#sf_params= np.array(sf_params, dtype=np.complex64)\n",
    "\n",
    "\n",
    "# Construct the symbolic Strawberry Fields program by\n",
    "# looping and applying layers to the program.\n",
    "with qnn.context as q:\n",
    "    for k in range(layers):\n",
    "        layer(sf_params[k], q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4d0ee5c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost(weights):\n",
    "    # Create a dictionary mapping from the names of the Strawberry Fields\n",
    "    # symbolic gate parameters to the TensorFlow weight values.\n",
    "    mapping = {p.name: w for p, w in zip(sf_params.flatten(), tf.reshape(weights, [-1]))}\n",
    "\n",
    "    # run the engine\n",
    "    state = eng.run(qnn, args=mapping).state\n",
    "    ket = state.ket()\n",
    "\n",
    "    difference = tf.reduce_sum(tf.abs(ket - target_state))\n",
    "    fidelity = tf.abs(tf.reduce_sum(tf.math.conj(ket) * target_state)) ** 2\n",
    "    return difference, fidelity, ket, tf.math.real(state.trace())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7b8fdd7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79cd6c90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rep: 0 Cost: 2.0001 Fidelity: 0.0000 Trace: 1.0000\n",
      "Rep: 1 Cost: 1.9978 Fidelity: 0.0001 Trace: 1.0000\n",
      "Rep: 2 Cost: 1.9897 Fidelity: 0.0002 Trace: 1.0000\n",
      "Rep: 3 Cost: 1.9794 Fidelity: 0.0006 Trace: 1.0000\n",
      "Rep: 4 Cost: 1.9681 Fidelity: 0.0010 Trace: 1.0000\n",
      "Rep: 5 Cost: 1.9632 Fidelity: 0.0016 Trace: 1.0000\n",
      "Rep: 6 Cost: 1.9563 Fidelity: 0.0023 Trace: 1.0000\n",
      "Rep: 7 Cost: 1.9476 Fidelity: 0.0031 Trace: 1.0000\n",
      "Rep: 8 Cost: 1.9377 Fidelity: 0.0041 Trace: 1.0000\n",
      "Rep: 9 Cost: 1.9268 Fidelity: 0.0052 Trace: 1.0000\n",
      "Rep: 10 Cost: 1.9196 Fidelity: 0.0064 Trace: 1.0000\n",
      "Rep: 11 Cost: 1.9130 Fidelity: 0.0077 Trace: 1.0000\n",
      "Rep: 12 Cost: 1.9055 Fidelity: 0.0091 Trace: 1.0000\n",
      "Rep: 13 Cost: 1.8971 Fidelity: 0.0107 Trace: 1.0000\n",
      "Rep: 14 Cost: 1.8880 Fidelity: 0.0124 Trace: 1.0000\n",
      "Rep: 15 Cost: 1.8789 Fidelity: 0.0142 Trace: 1.0000\n",
      "Rep: 16 Cost: 1.8695 Fidelity: 0.0162 Trace: 1.0000\n",
      "Rep: 17 Cost: 1.8601 Fidelity: 0.0183 Trace: 1.0000\n",
      "Rep: 18 Cost: 1.8505 Fidelity: 0.0205 Trace: 1.0000\n",
      "Rep: 19 Cost: 1.8410 Fidelity: 0.0229 Trace: 1.0000\n",
      "Rep: 20 Cost: 1.8327 Fidelity: 0.0254 Trace: 1.0000\n",
      "Rep: 21 Cost: 1.8241 Fidelity: 0.0280 Trace: 1.0000\n",
      "Rep: 22 Cost: 1.8145 Fidelity: 0.0308 Trace: 1.0000\n",
      "Rep: 23 Cost: 1.8060 Fidelity: 0.0337 Trace: 1.0000\n",
      "Rep: 24 Cost: 1.7979 Fidelity: 0.0367 Trace: 1.0000\n",
      "Rep: 25 Cost: 1.7897 Fidelity: 0.0398 Trace: 1.0000\n",
      "Rep: 26 Cost: 1.7815 Fidelity: 0.0431 Trace: 1.0000\n",
      "Rep: 27 Cost: 1.7732 Fidelity: 0.0464 Trace: 1.0000\n",
      "Rep: 28 Cost: 1.7649 Fidelity: 0.0498 Trace: 1.0000\n",
      "Rep: 29 Cost: 1.7566 Fidelity: 0.0533 Trace: 1.0000\n",
      "Rep: 30 Cost: 1.7484 Fidelity: 0.0569 Trace: 1.0000\n",
      "Rep: 31 Cost: 1.7403 Fidelity: 0.0606 Trace: 1.0000\n",
      "Rep: 32 Cost: 1.7322 Fidelity: 0.0644 Trace: 1.0000\n",
      "Rep: 33 Cost: 1.7242 Fidelity: 0.0683 Trace: 1.0000\n",
      "Rep: 34 Cost: 1.7164 Fidelity: 0.0723 Trace: 1.0000\n",
      "Rep: 35 Cost: 1.7087 Fidelity: 0.0763 Trace: 1.0000\n",
      "Rep: 36 Cost: 1.7012 Fidelity: 0.0804 Trace: 1.0000\n",
      "Rep: 37 Cost: 1.6938 Fidelity: 0.0846 Trace: 1.0000\n",
      "Rep: 38 Cost: 1.6866 Fidelity: 0.0888 Trace: 1.0000\n",
      "Rep: 39 Cost: 1.6795 Fidelity: 0.0931 Trace: 1.0000\n",
      "Rep: 40 Cost: 1.6726 Fidelity: 0.0975 Trace: 1.0000\n",
      "Rep: 41 Cost: 1.6659 Fidelity: 0.1019 Trace: 1.0000\n",
      "Rep: 42 Cost: 1.6593 Fidelity: 0.1063 Trace: 1.0000\n",
      "Rep: 43 Cost: 1.6529 Fidelity: 0.1108 Trace: 1.0000\n",
      "Rep: 44 Cost: 1.6467 Fidelity: 0.1154 Trace: 1.0000\n",
      "Rep: 45 Cost: 1.6405 Fidelity: 0.1199 Trace: 1.0000\n",
      "Rep: 46 Cost: 1.6346 Fidelity: 0.1245 Trace: 1.0000\n",
      "Rep: 47 Cost: 1.6287 Fidelity: 0.1291 Trace: 1.0000\n",
      "Rep: 48 Cost: 1.6230 Fidelity: 0.1337 Trace: 1.0000\n",
      "Rep: 49 Cost: 1.6173 Fidelity: 0.1383 Trace: 1.0000\n",
      "Rep: 50 Cost: 1.6117 Fidelity: 0.1430 Trace: 1.0000\n",
      "Rep: 51 Cost: 1.6062 Fidelity: 0.1476 Trace: 1.0000\n",
      "Rep: 52 Cost: 1.6007 Fidelity: 0.1523 Trace: 1.0000\n",
      "Rep: 53 Cost: 1.5952 Fidelity: 0.1569 Trace: 1.0000\n",
      "Rep: 54 Cost: 1.5897 Fidelity: 0.1616 Trace: 1.0000\n",
      "Rep: 55 Cost: 1.5842 Fidelity: 0.1662 Trace: 1.0000\n",
      "Rep: 56 Cost: 1.5786 Fidelity: 0.1708 Trace: 1.0000\n",
      "Rep: 57 Cost: 1.5731 Fidelity: 0.1754 Trace: 1.0000\n",
      "Rep: 58 Cost: 1.5674 Fidelity: 0.1800 Trace: 1.0000\n",
      "Rep: 59 Cost: 1.5617 Fidelity: 0.1846 Trace: 1.0000\n",
      "Rep: 60 Cost: 1.5560 Fidelity: 0.1892 Trace: 1.0000\n",
      "Rep: 61 Cost: 1.5502 Fidelity: 0.1938 Trace: 1.0000\n",
      "Rep: 62 Cost: 1.5445 Fidelity: 0.1984 Trace: 1.0000\n"
     ]
    }
   ],
   "source": [
    "# Disable eager execution\n",
    "#tf.compat.v1.disable_eager_execution()\n",
    "\n",
    "\n",
    "# set up the optimizer\n",
    "opt = tf.keras.optimizers.Adam()\n",
    "cost_before, fidelity_before, _, _ = cost(weights)\n",
    "\n",
    "# Perform the optimization\n",
    "for i in range(1000):\n",
    "    # reset the engine if it has already been executed\n",
    "    if eng.run_progs:\n",
    "        eng.reset()\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        loss, fid, ket, trace = cost(weights)\n",
    "\n",
    "    # one repetition of the optimization\n",
    "    gradients = tape.gradient(loss, weights)\n",
    "    opt.apply_gradients(zip([gradients], [weights]))\n",
    "\n",
    "    # Prints progress at every rep\n",
    "    if i % 1 == 0:\n",
    "        print(\"Rep: {} Cost: {:.4f} Fidelity: {:.4f} Trace: {:.4f}\".format(i, loss, fid, trace))\n",
    "\n",
    "\n",
    "print(\"\\nFidelity before optimization: \", fidelity_before.numpy())\n",
    "print(\"Fidelity after optimization: \", fid.numpy())\n",
    "print(\"\\nTarget state: \", target_state.numpy())\n",
    "print(\"Output state: \", np.round(ket.numpy(), decimals=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec9be0fb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
